---
categories: [知识梳理]
---
# Kafka知识梳理

## 一、消息队列

1. 概念：一种异步的服务间通信方式
2. 应用场景
   1. 应用解耦

      ![应用解耦](https://cdn.jsdelivr.net/gh/n20u/PicBed/blogs/knowledge_combing/20220815201123.png)
   2. 异步处理

      ![异步处理](https://cdn.jsdelivr.net/gh/n20u/PicBed/blogs/knowledge_combing/20220815201138.png)
   3. 流量削峰

      ![流量削峰](https://cdn.jsdelivr.net/gh/n20u/PicBed/blogs/knowledge_combing/20220815201201.png)
   4. 消息通讯
      聊天室。

## 二、Kafka

1. 应用场景
   1. 消息系统
   2. 存储系统
   3. 流式处理平台
2. 体系架构：一个典型的 Kafka 体系架构包括若干 Producer、若干 Broker、若干 Consumer，以及一个ZooKeeper集群，如下图所示。
   
   ![Kafka体系结构](https://cdn.jsdelivr.net/gh/n20u/PicBed/blogs/knowledge_combing/20220815202009.png)
   
   其中ZooKeeper是Kafka用来负责集群元数据的管理、控制器的选举等操作的。Producer将消息发送到Broker，Broker负责将收到的消息存储到磁盘中，而Consumer负责从Broker订阅并消费消息。
3. 基本概念
   - Kafka中的消息以主题(Topic)为单位进行归类，主题还可以细分为多个分区(Partition)。一个主题中的分区可以分布在不同的服务器(broker)上，以此来提供比单个broker更强大的性能。
   - Kafka 为分区引入了多副本(Replica)机制，副本之间是“一主多从”的关系，其中leader副本负责处理读写请求，follower副本只负责与leader副本的消息同步。
   - 分区中的所有副本统称为AR(Assigned Replicas)。与leader副本保持一定程度同步的副本(包括leader副本在内)组成ISR(In-Sync Replicas)，与leader副本同步滞后过多的副本(不包括leader副本)组成OSR(Out-of-Sync Replicas)，由此可见，AR=ISR+OSR。
   - 消息在被追加到分区日志文件的时候都会分配一个特定的偏移量(offset)。LEO是Log End Offset的缩写，它标识分区日志文件中下一条待写入消息的offset。HW是High Watermark的缩写，俗称高水位，分区ISR集合中最小的LEO即为分区的HW，对消费者而言只能消费HW之前的消息。

## 三、生产者

1. 客户端开发
   1. 配置生产者客户端参数及创建相应的生产者实例；
   2. 构建待发送的消息；

      ```Java
      public ProducerRecord(String topic, Integer partition, Long timestamp, K key, V value, Iterable<Header> headers);
      public ProducerRecord(String topic, Integer partition, Long timestamp, K key, V value);
      public ProducerRecord(String topic, Integer partition, K key, V value, Iterable<Header> headers);
      public ProducerRecord(String topic, Integer partition, K key, V value);
      public ProducerRecord(String topic, K key, V value);
      public ProducerRecord(String topic, V value);
      ```

   3. 发送消息；
      发送消息主要有三种模式：发后即忘(fire-and-forget)、同步(sync)及异步(async)。

      ```Java
      public Future<RecordMetadata> send(ProducerRecord<K, V> record);
      public Future<RecordMetadata> send(ProducerRecord<K, V> record, Callback callback);
      ```

      消息在通过send()方法发往broker的过程中，有可能需要经过拦截器(Interceptor)、序列化器(Serializer)和分区器(Partitioner)的一系列作用之后才能被真正地发往broker。
         - 生产者拦截器
           生产者拦截器既可以用来在消息发送前做一些准备工作，比如按照某个规则过滤不符合要求的消息、修改消息的内容等，也可以用来在发送回调逻辑前做一些定制化的需求，比如统计类工作。
           生产者拦截器需要实现org.apache.kafka.clients.producer.ProducerInterceptor\<K, V\>接口：

           ```Java
           ProducerRecord<K, V> onSend(ProducerRecord<K, V> record);
           void onAcknowledgement(RecordMetadata metadata, Exception exception);
           void close();
           ```

           ProducerInterceptor接口还有一个父接口org.apache.kafka.common.Configurable：

           ```Java
           void configure(Map<String, ?> configs);
           ```

         - 序列化器
           生产者需要用序列化器(Serializer)把对象转换成字节数组才能通过网络发送给Kafka。
           序列化器需要实现org.apache.kafka.common.serialization.Serializer\<T\>接口：

           ```Java
           void configure(Map<String, ?> configs, boolean isKey);
           byte[] serialize(String topic, T data);
           void close();
           ```

         - 分区器
           如果消息ProducerRecord中指定了partition字段，那么就不需要分区器的作用。否则就需要依赖分区器来计算partition的值。分区器的作用就是为消息分配分区。
           分区器需要实现org.apache.kafka.clients.producer.Partitioner接口：

           ```Java
           public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster);
           public void close();
           ```

           Partitioner接口与ProducerInterceptor接口一样，也有一个同样的父接口Configurable。

   4. 关闭生产者实例。
2. 原理分析
   1. 整体架构
      
      ![生产者客户端的架构](https://cdn.jsdelivr.net/gh/n20u/PicBed/blogs/knowledge_combing/20220817204537.png)

      1. 在生产者客户端的主线程中，由KafkaProducer创建消息，然后通过可能的拦截器、序列化器和分区器的作用之后缓存到消息累加器(RecordAccumulator，也称为消息收集器)中；
      2. 在RecordAccumulator的内部为每个分区都维护了一个双端队列，队列中的元素是ProducerBatch，即Deque＜ProducerBatch＞。消息写入缓存时，追加到其所属分区对应的双端队列的尾部；Sender线程读取消息时，从双端队列的头部读取。通过缓存消息使得Sender线程可以批量发送，从而减少网络传输的资源消耗以提升性能；
      3. Sender线程从RecordAccumulator中获取缓存的消息之后，会将原本＜分区，Deque＜ProducerBatch＞＞的保存形式转变成＜Node，List＜ ProducerBatch＞的形式，再封装成＜Node，Request＞的形式，这样就可以将Request请求发往各个Node了；
      4. 请求在从Sender线程发往Kafka之前还会保存到InFlightRequests中，InFlightRequests保存对象的具体形式为 Map＜NodeId，Deque＜Request＞＞，它的主要作用是缓存已经发出去但还没有收到响应的请求。
   2. 元数据的更新
      每个Node在InFlightRequests中还未确认的请求数量代表了该节点的负载，负载最小的节点为leastLoadedNode。当需要更新元数据时，会先挑选出leastLoadedNode，然后向这个Node发送MetadataRequest请求来获取具体的元数据信息。
      元数据：Kafka集群的元数据，这些元数据具体记录了集群中有哪些主题，这些主题有哪些分区，每个分区的leader副本分配在哪个节点上，follower副本分配在哪些节点上，哪些副本在AR、ISR等集合中，集群中有哪些节点，控制器节点又是哪一个等信息。

## 三、消费者

1. 消费者与消费组
   - 在Kafka的消费理念中，有消费者和消费组两层概念，每个消费者只隶属于一个消费组。消费组负责订阅Kafka中的主题，主题中的分区按照*分区分配策略*分配给消费组中的消费者。当消息发布到主题后，会被投递给订阅它的每个消费组中的某一个消费者。
   - 消费组是一个逻辑上的概念，每个消费组都会有一个固定的名称，消费者在进行消费前需要指定其所属消费组的名称；消费者并非逻辑上的概念，它是实际的应用实例，可以是一个线程或进程。
2. 客户端开发
   1. 配置消费者客户端参数及创建相应的消费者实例；
   2. 订阅主题

      ```Java
      // 集合订阅
      public void subscribe(Collection<String> topics, ConsumerRebalanceListener listener);
      public void subscribe(Collection<String> topics);
      // 正则表达式订阅
      public void subscribe(Pattern pattern, ConsumerRebalanceListener listener);
      public void subscribe(Pattern pattern);
      // 指定分区订阅
      public void assign(Collection<TopicPartition> partitions);
      ```

      再均衡监听器ConsumerRebalanceListener是一个包含2个方法的接口：

      ```Java
      void onPartitionsRevoked(Collection＜TopicPartition＞partitions); // 在再均衡开始之前和消费者停止读取消息之后被调用
      void onPartitionsAssigned(Collection＜TopicPartition＞partitions); // 在重新分配分区之后和消费者开始读取消费之前被调用
      ```

   3. 拉取消息并消费；
      Kafka中消息的消费是基于拉模式的，是一个不断轮询的过程，消费者重复地调用poll()方法得到所订阅的主题（分区）上的一组消息。

      ```Java
      public ConsumerRecords<K, V> poll(final Duration timeout);
      ```

      指定消费位移

      ```Java
      public void seek(TopicPartition partition, long offset);
      ```

      消费者拦截器主要在消费到消息或在提交消费位移时进行一些定制化的操作，需要实现org.apache.kafka.clients.consumer.ConsumerInterceptor\<K, V\>接口：

      ```Java
      ConsumerRecords<K,V> onConsume(ConsumerRecords<K,V> records);
      void onCommit(Map<TopicPartition, OffsetAndMetadata> offsets);
      void close();
      ```

      反序列化器需要实现Deserializer\<T\>接口：

      ```Java
      public void configure(Map<String, ?> configs, boolean isKey);
      public byte[] serialize(String topic, T data);
      public void close();
      ```

      控制或关闭消费：

         ```Java
         //暂停某些分区在拉取操作时返回数据给客户端
         public void pause(Collection<TopicPartition> partitions);
         //返回被暂停的分区集合
         public Set<TopicPartition> paused();
         //恢复某些分区向客户端返回数据
         public void resume(Collection<TopicPartition> partitions);
         ```

   4. 提交消费位移；
      - 自动提交
         消费者每隔5秒会将拉取到的每个分区中最大的消息位移进行提交，该动作是在poll()方法的逻辑里完成的。
      - 手动提交
        - 同步提交

            ```Java
            public void commitSync();
            public void commitSync(final Map<TopicPartition, OffsetAndMetadata> offsets);
            ```

        - 异步提交

            ```Java
            public void commitAsync();
            public void commitAsync(OffsetCommitCallback callback);
            public void commitAsync(final Map<TopicPartition, OffsetAndMetadata> offsets, OffsetCommitCallback callback);
            ```

   5. 关闭消费者实例。

      ```Java
      public void close();
      public void close(Duration timeout);
      ```

   6. 多线程实现：KafkaConsumer是非线程安全的。一个线程对应一个KafkaConsumer实例，称之为消费线程。
      - 一个消费线程消费一个或多个分区中的消息，所有的消费线程都隶属于同一个消费组。
      - 多个消费线程同时消费同一个分区，通过assign()、seek()等方法实现。
      - 一个消费线程拉取一个或多个分区中的消息，将处理消息模块改成多线程的实现方式，可以基于滑动窗口实现位移提交。

## 四、主题与分区

1. 主题的管理
   1. 创建主题
      - 使用kafka-topics.sh脚本创建主题的指令格式：`kafka-topic.sh --zookeeper <String:hosts> --create --topic [String:topic] --partitions <Integer: # of partitions> --replication-factor <Integer: replication factor>`。
      - 可以通过replica-assignment参数来手动指定分区副本的分配方案。
      - 可以通过config参数来设置所要创建主题的相关参数。
   2. 分区副本的分配
   3. 查看主题
      - 通过list指令可以查看当前所有可用的主题：`kafka-topic.sh --zookeeper <String:hosts> --list`。
      - 查看分区副本的分配细节：`kafka-topic.sh --zookeeper <String:hosts> --describe --topic [String:topic]`。
   4. 修改主题：通过alter指令可以修改主题，比如修改分区个数、修改配置等。
   5. 配置管理：kafka-configs.sh脚本是专门用来对配置进行操作的，包含变更配置alter和查看配置describe这两种指令类型。不仅可以支持操作主题相关的配置，还可以支持操作broker、用户和客户端这3个类型的配置。
   6. 删除主题：kafka-topics.sh脚本中的delete指令可以用来删除主题。
2. KafkaAdminClient
   - 创建主题：`CreateTopicsResult createTopics(Collection<NewTopic> newTopics);`。
   - 删除主题：`DeleteTopicsResult deleteTopics(Collection<String> topics);`。
   - 列出所有可用的主题：`ListTopicsResult listTopics();`。
   - 查看主题的信息：`DescribeTopicsResult describeTopics(Collection<String> topicNames);`。
   - 查询配置信息：`DescribeConfigsResult describeConfigs(Collection<ConfigResource> resources);`。
   - 修改配置信息：`AlterConfigsResult alterConfigs(Map<ConfigResource，Config> configs);`。
   - 增加分区：`CreatePartitionsResult createPartitions(Map<String，NewPartitions> newPartitions);`。
3. 分区的管理
   1. 优先副本的选举
      - 优先副本：在AR集合列表中的第一个副本。理想情况下，优先副本就是该分区的leader副本。
      - Kafka中kafka-perferred-replica-election.sh脚本提供了对分区leader副本进行重新平衡的功能，还提供了path-to-json-file参数来小批量地对部分分区执行优先副本的选举操作。
   2. 分区重分配
      - Kafka提供了kafka-reassign-partitions.sh脚本来执行分区重分配的工作，它可以在集群扩容、broker节点失效的场景下对分区进行迁移。
      - kafka-reassign-partitions.sh脚本的使用分为3个步骤：首先创建需要一个包含主题清单的JSON文件，其次根据主题清单和broker节点清单生成一份重分配方案，最后根据这份方案执行具体的重分配动作。
   3. 复制限流：kafka-config.sh脚本和kafka-reassign-partitions.sh脚本。
   4. 修改副本因子：kafka-reassign-partition.sh脚本。

## 五、日志存储

1. 文件目录布局
   一个主题有若干个分区，每个分区对应一个日志(Log)，每个日志(Log)对应于磁盘上的一个命名形式为\<topic\>-\<partition\>的文件夹。一个日志(Log)内包含多个日志分段(LogSegment)，向Log中追加消息时是顺序写入的，只有最后一个LogSegment才能执行写入操作。
   为了便于消息的检索，每个LogSegment中的日志文件(以".log"为文件后缀)都有对应的两个索引文件：偏移量索引文件(以“.index”为文件后缀)和时间戳索引文件(以“.timeindex”为文件后缀)。
2. 日志格式
   
   ![v2版本的消息结构](https://cdn.jsdelivr.net/gh/n20u/PicBed/blogs/knowledge_combing/20220823205956.png)

3. 日志索引
   偏移量索引文件用来建立消息偏移量(offset)到物理地址之间的映射关系，方便快速定位消息所在的物理文件位置；时间戳索引文件则根据指定的时间戳(timestamp)来查找对应的偏移量信息。
   Kafka中的索引文件以稀疏索引(sparse index)的方式构造消息的索引，每当写入一定量(由broker端参数log.index.interval.bytes指定，默认值为4096，即4KB)的消息时，偏移量索引文件和时间戳索引文件分别增加一个偏移量索引项和时间戳索引项。查询索引时使用二分查找法进行查询。
   Kafka的每个日志对象中使用了ConcurrentSkipListMap来保存各个日志分段，每个日志分段的baseOffset作为key，这样可以根据指定偏移量来快速定位到消息所在的日志分段。
4. 日志清理
   Kafka提供了两种日志清理策略：
   1. 日志删除(Log Retention)：按照一定的保留策略直接删除不符合条件的日志分段。
      - 基于时间：日志删除任务会检查当前日志文件中是否有保留时间超过设定的阈值(retentionMs)来寻找可删除的日志分段文件集合(deletableSegments)。
         
         ![基于时间的保留策略](https://cdn.jsdelivr.net/gh/n20u/PicBed/blogs/knowledge_combing/20220823222639.png)

      - 基于日志大小：日志删除任务会检查当前日志的大小是否超过设定的阈值(retentionSize)来寻找可删除的日志分段的文件集合(deletableSegments)。
         
         ![基于日志大小的保留策略](https://cdn.jsdelivr.net/gh/n20u/PicBed/blogs/knowledge_combing/20220823223439.png)

      - 基于日志起始偏移量：基于日志起始偏移量的保留策略的判断依据是某日志分段的下一个日志分段的起始偏移量baseOffset是否小于等于logStartOffset，若是，则可以删除此日志分段。
  
         ![基于日志起始偏移量的保留策略](https://cdn.jsdelivr.net/gh/n20u/PicBed/blogs/knowledge_combing/20220823223843.png)

      删除日志分段时，首先会从Log对象中所维护日志分段的跳跃表中移除待删除的日志分段，以保证没有线程对这些日志分段进行读取操作。然后将日志分段所对应的所有文件添加上“.deleted”的后缀。最后交由一个以“delete-file”命名的延迟任务来删除这些以“.deleted”为后缀的文件。
   2. 日志压缩(Log Compaction)：针对每个消息的key进行整合，对于有相同key的不同value值，只保留最后一个版本。
      每一个日志目录下都有一个名为“cleaner-offset-checkpoint”的清理检查点文件，用来记录每个主题的每个分区中已清理的偏移量。通过清理检查点文件可以将Log分成一个已经清理过的clean部分和一个还未清理过的dirty部分。
      Kafka中的每个日志清理线程会使用一个名为“SkimpyOffsetMap”的对象来构建key的哈希值与最后出现的offset的映射关系的哈希表，然后检查每个消息是否符合保留条件，如果符合就保留下来，否则就会被清理。
      当需要删除一个key时，Kafka提供了一个墓碑消息(tombstone)的概念，也即消息的key不为null，但是其value为null。
      Log Compaction执行过后的日志分段的大小会比原先的日志分段的要小，为了防止出现太多的小文件，Kafka会将日志分段进行分组，同一个组的多个日志分段清理过后，只会生成一个新的日志分段。
   3. 磁盘存储
      1. 页缓存：把磁盘中的数据缓存到内存中，把对磁盘的访问变为对内存的访问。使用文件系统并依赖于页缓存的做法明显要优于维护一个进程内缓存或其他结构，至少可以省去了一份进程内部的缓存消耗，同时还可以通过结构紧凑的字节码来替代使用对象的方式以节省更多的空间。Kafka中大量使用了页缓存，这是Kafka实现高吞吐的重要因素之一。
      2. 磁盘I/O流程：从编程角度而言，一般磁盘I/O的场景有以下四种：
         1. 用户调用标准C库进行I/O操作，数据流为：应用程序buffer→C库标准IObuffer→文件系统页缓存→通过具体文件系统到磁盘。
         2. 用户调用文件I/O，数据流为：应用程序 buffer→文件系统页缓存→通过具体文件系统到磁盘。
         3. 用户打开文件时使用O_DIRECT，绕过页缓存直接读写磁盘。
         4. 用户使用类似dd工具，并使用direct参数，绕过系统cache与文件系统直接写磁盘。

         ![磁盘I/O的流程](https://cdn.jsdelivr.net/gh/n20u/PicBed/blogs/knowledge_combing/20220823230929.png)
      3. 零拷贝：将数据直接从磁盘文件复制到网卡设备中，而不需要经由应用程序之手，减少了内核和用户模式之间的上下文切换。
         对Linux操作系统而言，零拷贝技术依赖于底层的sendfile()方法实现。对应于Java语言，FileChannal.transferTo()方法的底层实现就是sendfile()方法。
         
         非零拷贝技术：

            ![非零拷贝技术](https://cdn.jsdelivr.net/gh/n20u/PicBed/blogs/knowledge_combing/20220823231634.png)
         
         零拷贝技术：

            ![零拷贝技术](https://cdn.jsdelivr.net/gh/n20u/PicBed/blogs/knowledge_combing/20220823231655.png)

         零拷贝技术通过DMA(Direct Memory Access)技术将文件内容复制到内核模式下的Read Buffer中。不过没有数据被复制到Socket Buffer，相反只有包含数据的位置和长度的信息的文件描述符被加到Socket Buffer中。DMA引擎直接将数据从内核模式中传递到网卡设备(协议引擎)。

## 六、服务端

1. 协议设计：Kafka自定义了一组基于TCP的二进制协议，只要遵守这组协议的格式，就可以向Kafka发送消息、拉取消息、提交消费位移等。
2. 时间轮
   Kafka中的时间轮(TimingWheel)是一个存储定时任务的环形队列，底层采用数组实现，数组中的元素是定时任务列表(TimerTaskList)。TimerTaskList是一个环形的双向链表，链表中的每一项表示的都是定时任务项(TimerTaskEntry)，其中封装了真正的定时任务(TimerTask)。
   时间轮由多个时间格组成，每个时间格代表当前时间轮的基本时间跨度(tickMs)。时间轮的时间格个数是wheelSize，那么整个时间轮的总体时间跨度(interval)为tickMs×wheelSize。时间轮还有一个表示当前所处时间的表盘指针(currentTime)。
   Kafka引入了层级时间轮的概念，上层时间轮的基本时间跨度等于当前时间轮总体时间跨度，当任务的到期时间超过了当前时间轮所表示的时间范围时，就会尝试添加到上层时间轮中。
   Kafka中的定时器借了JDK中的DelayQueue来协助推进时间轮，将每个使用到的TimerTaskList都加入DelayQueue，有一个"收割机"线程来获取DelayQueue中到期的任务列表TimerTaskList，之后既可以根据TimerTaskList的expiration来推进时间轮的时间，也可以对里面的TimerTaskEntry该执行过期操作的就执行过期操作，该降级时间轮的就降级时间轮。
3. 延时操作
   在Kafka中有多种延时操作，比如延时生产(DelayedProduce)、延时拉取(DelayedFetch)、延时数据删除(DelayedDeleteRecords)等。延时操作需要延时返回响应的结果，必须有一个超时时间(delayMs)，还要能够支持外部事件的触发。
   延时操作创建之后会被加入延时操作管理器(DelayedOperationPurgatory)来做专门的处理。每个延时操作管理器都会配备一个定时器(SystemTimer)来做超时管理，底层采用时间轮(TimingWheel)实现。延时操作管理器会启动“收割机”线程ExpiredOperationReaper来驱动时间轮的轮转，还会配备一个监听池来负责监听每个分区的外部事件。
4. 控制器
   在Kafka集群中会有一个或多个broker，其中有一个broker会被选举为控制器(Kafka Controller)，它负责管理整个集群中所有分区和副本的状态。
   1. 控制器的选举及异常恢复：afka中的控制器选举工作依赖于ZooKeeper，成功竞选为控制器的broker会在ZooKeeper中创建/controller这个临时(EPHEMERAL)节点。
   2. 优雅关闭：Kafka在bin目录下存放了一个脚本工具kafka-server-stop.sh来优雅地关闭Kafka。Kafka服务入口程序中有一个名为“kafka-shutdown-hock”的关闭钩子，待Kafka进程捕获终止信号的时候会执行这个关闭钩子中的内容，其中除了正常关闭一些必要的资源，还会执行一个控制关闭(ControlledShutdown)的动作。使用ControlledShutdown的方式关闭Kafka有两个优点：一是可以让消息完全同步到磁盘上，在服务下次重新上线时不需要进行日志的恢复操作；二是ControllerShutdown在关闭服务之前，会对其上的leader副本进行迁移，这样就可以减少分区的不可用时间。
   3. 分区leader的选举：按照AR集合中副本的顺序查找第一个存活的副本，并且这个副本在ISR集合中。

## 七、客户端

1. 分区分配策略
   1. RangeAssignor分配策略：按照消费者总数和分区总数进行整除运算来获得一个跨度，然后将分区按照跨度进行平均分配，以保证分区尽可能均匀地分配给所有的消费者。
   2. RoundRobinAssignor分配策略：将消费组内所有消费者及消费者订阅的所有主题的分区按照字典序排序，然后通过轮询方式逐个将分区依次分配给每个消费者。
   3. StickyAssignor分配策略：主要有两个目的：分区的分配要尽可能均匀；分区的分配尽可能与上次分配的保持相同。
   4. 自定义分区分配策略：自定义的分配策略必须要实现org.apache.kafka.clients.consumer.internals.PartitionAssignor接口。
2. 消费者协调器和组协调器
   1. 旧版消费者客户端的问题
      1. 羊群效应(Herd Effect)：ZooKeeper中一个被监听的节点变化，大量的Watcher通知被发送到客户端，导致在通知期间的其他操作延迟，也有可能发生类似死锁的情况。
      2. 脑裂问题(Split Brain)：消费者进行再均衡操作时每个消费者都与ZooKeeper进行通信以判断消费者或broker变化的情况，由于ZooKeeper本身的特性，可能导致在同一时刻各个消费者获取的状态不一致，这样会导致异常问题发生。
   2. 再均衡的原理：将全部消费组分成多个子集，每个消费组的子集在服务端对应一个GroupCoordinator对其进行管理，GroupCoordinator是Kafka服务端中用于管理消费组的组件。而消费者客户端中的ConsumerCoordinator组件负责与GroupCoordinator进行交互。
3. __consumer_offsets：位移提交的内容最终会保存到Kafka的内部主题__consumer_offsets中。
4. 事务
