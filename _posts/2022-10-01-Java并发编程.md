---
categories: [知识梳理]
---
# Java并发编程

## 一、Java线程

1. 在Java中使用多线程
   1. 实现Runnable接口创建线程
      ```Java
      public class RunnableThreadExample implements Runnable {
          public void run() {
              System.out.println("RunnableThreadExample.run")
          }
          public static void main(String[] args) {
              Thread thread = new Thread(new RunnableThreadExample());
              thread.start()
          }
      }
      ```
   2. 继承Thread类创建线程
      ```Java
      public class ThreadExample extends Thread {
          public void run() {
              System.out.println("ThreadExample.run")
          }
          public static void main(String[] args) {
              ThreadExample example = new ThreadExample();
              example.start()
          }
      }
      ```
   3. 实现Callable接口并创建带返回值的线程
      Java中提供了Callable和Future来创建有返回值的线程。
      ```Java
      public class CallableExample implements Callable<String> {
          @Override
          public String call() throws Exception {
              return "执行结果:SUCCESS";
          }
          public static void main(String[] args) throws ExecutionException, InterruptedException {
              CallableExample callableExample = new CallableExample();
              FutureTask<String> futureTask = new FutureTask<>(callableExample);
              Thread thread = new Thread(futureTask);
              thread.start();
              System.out.printf("result:%s", futureTask.get());
          }
      }
      ```
2. 多线程的基本原理
   当执行new Thread().start()方法启动线程时，会先在JVM层面创建一个线程，JVM具有跨平台特性，它会根据当前操作系统的类型调用相关指令来创建线程并启动。
   线程启动后，并不会立刻运行，而是要等到操作系统层面的CPU调度算法，把当前线程分配给某个CPU来执行。线程被分配执行后，会回调线程中的run()方法执行相关指令。
3. 线程的运行状态
   线程从启动到最终销毁，整个生命周期会经历不同的状态，在Java中，线程一共有6种状态：
   - NEW，新建状态，也就是调用new Thread()时的状态。
   - RUNNABLE，运行状态，通过start()方法启动线程后的状态。
   - BLOCKED，阻塞状态，当线程执行synchronized代码，并且未抢占到同步锁时，会变成该状态。
   - WAITING，调用Object.wait()等方法，会让线程变成该状态。
   - TIMED_WAITING，超时等待状态，如sleep(timeout)，超时后会自动唤醒。
   - TERMINATED，终止状态，线程的run()方法中的指令执行完成后的状态。

   ![Java线程的运行状态及触发状态变更的方法](https://cdn.jsdelivr.net/gh/n20u/PicBed/blogs/knowledge_combing/微信图片_20220922104628.jpg)
4. 正确终止线程
   1. Thread中有一个stop()方法，这个方法是不安全的，会导致两个问题：
      - 立即抛出ThreadDeath异常，在run()方法中任何一个执行指令都可能抛出ThreadDeath异常。
      - 会释放当前线程所持有的所有的锁，这种锁的释放是不可控的。
   2. 安全中断线程之interrupt
      1. 在Thread中提供了一个interrupt()方法，用来向指定线程发送中断信号，收到该信号的线程可以使用isInterrupted()方法来判断是否被中断。
      2. 如果线程因为sleep()、Object.wait()、Thread.join()、Thread.sleep()等方法阻塞，其他线程调用interrupt()方法中断该线程时，interrupt()方法会先唤醒被阻塞的线程，然后把线程中断状态进行复位，最后该线程会抛出InterruptedException异常。可以在捕获的异常中实现一些后置操作，最终决定是否要中断该线程。
         除InterruptedException被动触发线程复位外，还有一个Thread.interrupted()方法可以主动触发线程中断标识的复位。
      3. 实现原理：当其他线程调用interrupt()方法中断某线程时，会调用一个native方法修改JVM中定义的一个interrupted变量，被中断线程通过isInterrupted()方法来获得这个变量的值，进而判断当前的中断状态。interrupted字段使用了volatile修饰，表示它提供了可见性保障。
5. 上下文切换   
   1. 上下文切换类型
      - 进程上下文切换
        1. 原因：
           - CPU时间分配
           - 当进程系统资源（如内存）不足时，进程会被挂起。
           - 当存在优先级更高的进程运行时，当前进程有可能会被挂起，CPU时间片分配给优先级更高的进程运行。
        2. 进程的上下文切换，需要把用户空间中的虚拟内存、栈、全局变量等状态保存起来，还需要保存内核空间的内核堆栈、寄存器等状态。同时在加载下一个进程时，需要再次恢复上下文信息。
      - 线程上下文切换
        1. 原因：
           - 多个任务抢占synchronized同步锁资源。
           - 在线程运行过程中存在I/O阻塞，CPU调度器会切换CPU时间片。
           - 在线程中通过主动阻塞当前线程的方法释放CPU时间片。
           - 当前线程执行完成后释放CPU时间片，CPU重新调度。
        2. 当两个线程切换属于不同的进程时，由于进程资源不共享，所以线程的切换其实就是进程的切换。当两个线程属于同一个进程时，只需要保存线程的上下文，包括私有数据、寄存器、栈指针等数据。
      - 中断上下文切换
        1. 原因：
           - CPU本身故障、程序故障。
           - I/O中断。
        2. 为了快速响应硬件事件，中断处理会打断当前正常的进程调度和执行过程，此时CPU会调用中断处理程序响应中断事件。被打断的进程在切换之前只需要保存内核态中必需的状态，如CPU寄存器、内核堆栈等资源。
   2. 减少上下文切换
      - 减少线程数。
      - 采用无锁设计解决线程竞争问题。
      - 采用CAS做自旋操作。
6. 守护线程
   1. 概念：在Java中，线程可以分为两类：用户线程和守护线程。守护线程不会影响JVM进程的退出，而用户线程在有任务没有执行完成前，JVM进程不会退出直到所有用户线程运行结束。
   2. 应用场景
      - JVM垃圾回收器
      - 一些中间件的心跳检测、事件监听等涉及定时异步执行的场景
   3. 使用注意事项
      - 在Java中，线程的状态是自动继承的。
      - thread.setDaemon(true)必须在start()方法启动之前调用。
7. 快速定位并解决线程导致的生产问题
   1. 通过jps命令，查看Java进程的pid；
   2. 通过jstack \<pid\>命令查看进程dump日志。

   jstack是Java虚拟机自带的一种堆栈跟踪工具，它主要用于打印指定Java进程ID中当前时刻的线程dump日志，线程快照是当前Java虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的主要目的是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待。主要包含三个部分的内容：线程的基本信息、线程的运行状态、线程的堆栈信息。

## 二、synchronized同步锁

1. synchronized的修饰方法有两种：作用在方法级别、作用在代码块级别。synchronized提供了两种锁：类锁、对象锁。
2. 实现原理
   1. Mark Word
      Java对象存储结构可以分为三个部分：对象头、实例数据、对齐填充。对象头由三个部分组成：Mark Word、Klass Pointer、Length。Mark Word记录了与对象和锁相关的信息，当这个对象作为锁对象来实现synchronized的同步操作时，锁标记和相关信息都是存储在Mark Word中的。
      
      32位系统中Mark Word的存储结构：
      ![32位系统中Mark_Word的存储结构](https://cdn.jsdelivr.net/gh/n20u/PicBed/blogs/knowledge_combing/32位系统中Mark_Word的存储结构.jpg)
      64位系统中Mark Word的存储结构：
      ![64位系统中Mark_Word的存储结构](https://cdn.jsdelivr.net/gh/n20u/PicBed/blogs/knowledge_combing/64位系统中Mark_Word的存储结构.jpg)
   2. 锁类型
      1. 偏向锁：在没有多线程竞争的情况下访问synchronized修饰的代码块的加锁场景。
         - 获取原理
            - 没有锁竞争
               1. 从当前线程的栈中找到一个空闲的BasicObjectLock；
               2. 将BasicObjectLock中的oop指针指向当前的锁对象lock；
               3. 获得当前锁对象lock的对象头，通过对象头来判断是否可偏向，也就是说锁标记为101，并且Thread Id为空。
                  - 如果为可偏向状态，那么判断当前偏向的线程是不是自身，如果是，则可以直接运行同步代码块；否则先构建一个匿名偏向的Mark Word，然后通过CAS方法，把一个匿名偏向的Mark Word修改为偏向自身，如果当前锁对象lock已经偏向了其他线程，那么CAS一定会失败。
                  - 如果为不可偏向状态，则需要通过轻量级锁来完成锁的抢占过程。
            - 存在锁竞争
               1. 尝试撤销lock锁对象的偏向锁；
               2. 检查获得偏向锁的线程的状态。
                  - 该线程已经执行完同步代码块或者处于非存活状态，直接把偏向锁撤销恢复成无锁状态，然后本线程升级到轻量级锁，通过轻量级锁抢占锁资源。
                  - 该线程还在执行同步代码块中的指令，直接把锁对象lock升级成指向该线程的轻量级锁，接着该线程继续执行同步代码块中的代码。
         - 释放原理：只是把Lock Record释放了，当前锁对象lock仍然是偏向该线程的。
      2. 轻量级锁：没有抢占到锁的线程，进行一定次数的重试（自旋）。
         - 获取原理：
            1. 线程进入同步代码块后，JVM会给当前线程分配一个BasicObjectLock；
            2. 构建一个无锁状态的Mark Word，并设置到BasicObjectLock的displaced_header字段中；
            3. 通过CAS将lock锁对象的Mark Word替换为指向Lock Record的指针，如果替换成功，表示轻量级锁抢占成功；否则说明当前lock锁对象不是无锁状态，会触发锁膨胀，升级到重量级锁。
         - 释放原理：
            1. 通过CAS把Lock Record中displaced_header存储的lock锁对象的Mark Word替换到lock锁对象的Mark Word中；
            2. 如果CAS成功，则轻量级锁释放完成；
            3. 如果CAS失败，就会触发锁膨胀，完成锁膨胀之后，再调用重量级锁的释放锁方法，完成锁的释放过程。
      3. 重量级锁：如果没有抢占到锁的线程通过一定次数的自旋后，发现仍然没有获得锁，就只能阻塞等待了，所以最终会升级到重量级锁，通过系统层面的互斥量来抢占锁资源。
         - 获取原理：
            1. 判断当前线程是否是重入，如果是则增加重入次数；
            2. 如果不是重入，则通过自旋锁来实现锁的抢占，这里使用CAS机制来判断ObjectMonitor中的_owner字段是否为空，如果为空就表示重量级锁已释放，当前线程可以获得锁，否则就进行自适应自旋重试；
            3. 最后，如果通过自旋锁竞争锁失败，则会把当前线程构建成一个ObjectWaiter节点，插入_cxq队列的队首，再使用park方法阻塞当前线程。
         - 释放原理：
            1. 把ObjectMonitor中持有锁的对象_owner置为null；
            2. 从_cxq队列中使用unpark()唤醒一个处于锁阻塞的线程；
            3. 被唤醒的线程会重新竞争重量级锁。

## 三、volatile解决可见性和有序性问题

1. 可见性
   - 在多线程环境中导致可见性问题的根本原因是CPU的高速缓存及指令重排序。
      - 为了解决CPU的缓存一致性问题，CPU提供了总线锁、缓存锁的机制，只需要在总线上声明Lock#信号，CPU便会增加锁的机制来解决缓存一致性问题。
      - 为了避免CPU内存系统重排序问题，CPU提供了内存屏障指令，x86指令中的内存屏障包括：读屏障指令、写屏障指令、读写屏障指令。
   - 导致指令重排序的问题有编译器重排序、CPU内存系统重排序和CPU并行指令，而JVM提供了内存屏障方法来解决这些问题：
      | 屏障类型 |   实例   |      说明      |
      |:-------:|:--------:|:--------------|
      |LoadLoad Barriers|Load1;LoadLoad;Load2|确保在执行Load2及后续加载指令之前，先加载Load1的数据|
      |StoreStore Barriers|Store1;StoreStore;Store2|确保在执行Store2及后续存储指令之前，Store1的数据对其他处理器可见|
      |LoadStore Barriers|Load1;LoadStore;Store2|确保在执行Store2及后续存储指令之前，先加载Load1的数据|
      |StoreLoad Barriers|Store1;StoreLoad;Load2|确保在执行Load2及后续加载指令之前，Store1的数据对其他处理器可见|
   - volatile实现原理：
      - volatile关键字会在JVM层面声明一个C++的volatile，它能够防止JIT层面的指令重排序。
      - 在对修饰了volatile关键字的stop字段赋值后，JVM会调用storeload()屏障方法，该方法中声明了lock指令，该指令有两个作用，一是解决缓存一致性问题，二是实现内存屏障。
2. Happens-Before模型
   
   Java内存模型中的happens-before规则用来表示两个指令之间的可见性，如果a happens-before b，那么意味着a的结果对b可见。
   1. 程序顺序规则：在同一个线程中，存在两个操作x和y，并且x在源程序中排在y之前，这意味着x happens-before y。
   2. 传递性规则：如果A happens-before B且B happens-before C，则A happens-before C。
   3. volatile变量规则：通过内存屏障来保障一个volatile修饰的变量的写操作一定happens-before于其读操作。
   4. 监视器锁规则：一个线程对一个锁的释放锁操作一定happens-before于后续线程对该锁的加锁操作。
   5. start规则：假设一个线程A调用一个子线程的start()方法，那么线程A在调用start()方法之前的所有操作happens-before子线程中的任意操作。
   6. join规则：如果一个线程A调用一个子线程的join()方法，那么子线程中的任意操作happens-before线程A在调用join()方法之后的所有操作。

## 四、J.U.C中的重入锁和读写锁

1. ReentrantLock
   1. AbstractQueuedSynchronizer
      AbstractQueuedSynchronizer(简称AQS)是ReentrantLock实现锁同步的核心类，实际上在J.U.C中大部分组件都依赖于AbstractQueuedSynchronizer。
      AQS维护了一个volatile int state，用来表示共享资源，该属性在独占锁中有如下两个值：
         - state=0，表示当前锁资源空闲。
         - state>0，表示有线程已经抢占到锁但还没释放，在重入的情况下state有可能是一个大于1的值。
      state共享变量使用compareAndSetState()方法进行比较并修改，compareAndSetState()方法通过CAS乐观锁的方式来做比较并替换，能够保证多线程竞争的原子性。
      AQS是一个抽象类，在使用时需要继承该类，然后实现共享变量state的获取和释放，而AQS负责线程等待队列的维护和唤醒，具体需要重写的方法如下：
         - tryAcquire(int)：独占方式尝试获取资源。
         - tryRelease(int)：独占方式尝试释放资源。
         - tryAcquireShared(int)：共享方式尝试获取资源。
         - tryReleaseShared(int)：共享方式尝试释放资源。
   2. 实现原理
      1. 加锁
         1. ReentrantLock中定义了一个Sync的同步类，它是一个抽象的静态内部类，通过继承AQS来实现重入锁的逻辑。
            Sync类有两个具体实现：
               - NonfairSync，非公平锁，允许在不排队的情况下直接尝试通过CAS抢占锁，默认使用非公平锁。
               - FairSync：公平锁，必须按照FIFO的规则来访问锁资源。
         2. 在非公平锁中，如果CAS操作未成功，则说明有线程正在持有锁，此时继续调用acquire(1)方法；公平锁则直接调用acquire(1)方法。该方法主要逻辑如下：
            1. 通过tryAcquire()方法尝试获取独占锁，如果成功则返回true，否则返回false。
            2. 如果tryAcquire()方法返回false，则说明当前锁被占用，只能通过addWaiter()方法将当前线程封装成Node并添加到AQS的同步队列中。
            3. acquireQueued()方法将Node作为参数，通过自旋去尝试抢占锁，当抢不到锁时阻塞当前线程。
      2. 释放锁
         通过tryRelease()方法尝试释放独占锁，锁资源释放成功后，通过unparkSuccessor()方法唤醒同步队列中的线程。
2. ReentrantReadWriteLock
   ReentrantReadWriteLock基于AbstractQueuedSynchronizer的共享锁和排他锁功能来实现读写锁的功能。
   state采用高低位分开存储读锁和写锁，高16位存储读锁状态，即获得读锁的线程数量，低16位存储写锁状态，即获得写锁的线程的重入次数。
   1. WriteLock实现原理
      1. 加锁tryAcquire
         1. 如果有其他线程获得了共享锁(读锁)，这会导致写线程阻塞；
         2. 如果是线程重入，则通过w+exclusiveCount(acquires)进行重入次数的累加；
         3. 通过writerShouldBlock()方法判断写锁是否应该阻塞，在非公平模式下，写锁直接通过compareAndSetState()方法竞争锁。
      2. 释放锁tryRelease
         1. 通过getState()-release来递减锁的次数，由于写锁的重入次数保存在低位，所以直接按十进制计算即可；
         2. 通过exclusiveCount()方法计算写锁的重入次数，如果为0，则说明锁释放成功。
   2. ReadLock实现原理
      1. 加锁
         1. 先判断是否有其他线程获得写锁，如果有，则当前获取读锁的线程需要等待；
         2. 通过readerShouldBlock()方法判断读锁是否应该阻塞，判断当前线程是否是重入；
         3. 通过compareAndSetState()方法在高位增加读锁数量。
      2. 支持锁的降级，也就是从写锁降级到读锁。
3. StampedLock
   在StampedLock中，采用了一个long类型的state变量来表示同步状态，long类型的长度是64位。低7位表示读锁的状态，第8位表示写锁的状态，第9~64位存储stamp，记录写锁中的状态变化，每触发一次写锁，stamp就会加1。
   在StampedLock中没有使用AQS，而是自己实现了一个改造版本的同步队列。

## 五、条件等待

1. wait/notify
   1. 概念：Java提供了wait/notify机制来实现多个线程之间的协同处理，也就是控制线程之间的等待和唤醒。wait()/notify()/notifyAll()是属于Object对象中的方法：
      - wait()方法，使当前线程进入阻塞状态，并且释放持有的锁。
      - notify()方法，唤醒处于阻塞状态下的一个线程。
      - notifyAll()方法，唤醒处于阻塞状态下的所有线程。
   2. 原理：
      1. ThreadA在同步代码块中调用wait()方法，则先释放锁，然后把当前线程加入_WaitSet等待队列中；
      2. 由于ThreadA释放了锁，所以原本在同步队列中的ThreadB被唤醒竞争到锁，开始执行同步代码块中的逻辑；
      3. ThreadB调用notify()方法把等待队列中的ThreadA唤醒，ThreadA被从_WaitSet中移到同步队列中，重新去竞争锁资源；
      4. 直到ThreadB退出同步代码块之后释放锁，ThreadA又有机会竞争到锁。
   3. wait()/notify()和同步锁
      1. wait()/notify()方法必须要放在synchronized同步代码块中，有以下两个原因：
         - wait()/notify()方法是基于一个共享对象来实现线程间通信，这意味着存在多个线程对该共享对象的竞争，为了保证原子性，需要加锁。
         - wait()/notify()方法需要实现线程的阻塞和唤醒，synchronized本身实现了同步队列的机制，正好为wait()/notify()方法提供了很好的协同机制。
      2. 之所以将wait()/notify()方法放在Object中，是因为Java中任何一个Object都关联了一个监视器对象，能够很好地实现同步锁的机制。
2. Thread.join()方法是使用wait()/notify()方法来实现的。
3. Condition
   1. condition.await()
      1. 把当前线程添加到等待队列中；
      2. 彻底释放锁，把锁状态设置为0；
      3. 使用LockSupport.park(this)方法阻塞当前线程。
   2. condition.signal()方法把等待队列中等待最久的节点移动到AQS的CLH队列中。

## 六、J.U.C并发工具集

1. CountDownLatch
   1. 概念：CountDownLatch是一个线程同步工具类，它允许一个或多个线程一直处于等待状态，直到其他线程执行结束，它提供了两个核心方法：
      - countDown()方法，对计数器进行递减。
      - await()方法，使调用该方法的线程进入等待状态。
      CountDownLatch在构造时需要传递一个正整数，线程每调用一次countDown()方法，都会对该正整数减一。当计数器为0时，会唤醒所有处于await()方法阻塞的线程。
   2. 原理：CountDownLatch使用了AbstractQueuedSynchronizer的共享锁机制。
      1. await()：如果state字段的值不为0，则阻塞当前线程；否则直接返回不需要阻塞。
      2. countDown()：对state进行递减，直到state为0，则唤醒处于同步队列中被阻塞的线程。
2. Semaphore
   1. 概念：Semaphore用来限制对某个资源同时访问的线程数量，它有两个核心方法：
      - acquire()方法，获取一个令牌。
      - release()方法，释放一个令牌。
   2. 原理：Semaphore也是基于AQS中的共享锁来实现的，在构建Semaphore实例时传递的参数permits，其实是AQS中的state属性，每次调用acquire()方法，都是对state进行递减，当state=0时，意味着所有的令牌都被使用完了，后续的线程都会以共享锁类型添加到CLH队列中，当state>0时，说明有其他线程释放了令牌，可以从CLH队列中唤醒头部的线程。
3. CyclicBarrier
   1. 概念：CyclicBarrier的字面意思是可循环使用的屏障，它的主要作用是让一组线程到达一个屏障时被阻塞，直到最后一个线程到达屏障时，屏障才会打开，所有被屏障拦截的线程才会继续往下执行。
   2. 原理
      
      CyclicBarrier中定义了两个int类型的变量：
         - parties表示每次要求到达屏障点的线程数。
         - count用来实现内部的计数器，初始值就是parties，后续在每个线程调用await()方法时，会对count减一，当count为0时就会唤醒所有的线程。
      
      CyclicBarrier内部用到了ReentrantLock和Condition，CyclicBarrier中关于线程的阻塞和唤醒是采用Condition来完成的。

## 七、并发编程工具

1. ThreadLocal
   1. 概念：ThreadLocal为每个线程提供了一个独立的存储空间，用来存储共享变量的副本，每个线程只会对共享变量的副本进行操作，该操作对其他线程而言是不可见的。
      ThreadLocal中提供了四个方法，分别如下：
         - set(T value)，设置一个value，保存到当前线程的副本中。
         - get()，得到当前线程内保存的value。
         - remove()，移除当前线程内保存的value。
         - withInitial()，Java 8提供的方法，使用函数式接口来完成初始值的设置。
   2. 实现原理：在每个线程中都会维护一个成员变量ThreadLocalMap，其中key是一个指向ThreadLocal实例的弱引用、value表示ThreadLocal的初始化值或者在当前线程中set()方法的值。
2. Fork/Join
   1. 概念：Fork/Join是Java 1.7提供的一个任务拆分与聚合的工具，它可以把一个大任务拆分成多个子任务进行并行运算，再把拆分的子任务的计算结果进行合并。
      
      Fork/Join中具体的任务用ForkJoinTask类来表示，ForkJoinTask类中有如下几个重要的方法：
         - fork()，创建一个异步执行的子任务。
         - join()，等待任务完成后返回计算结果。
         - invoke()，开始执行任务，必要时等待其执行结果。
      
      针对Fork/Join还有专门用来运行ForkJoinTask的线程池ForkJoinPool，线程池中管理ForkJoinWorkerThread类型的工作线程，该线程池可以通过以下方法来运行具体的ForkJoinTask任务：
         - invoke(ForkJoinTask t)，提供任务并一直阻塞，直到任务执行完成返回合并结果。
         - execute(ForkJoinTask t)，异步执行任务，无返回值。
         - submit(ForkJoinTask t)，异步执行任务，返回Task本身，可以通过task.get()方法获取合并之后的结果。
   2. 实现原理

      通过ForkJoinPool或者ForkJoinTask提交任务后整个Fork/Join的执行流程：
         1. 提交任务后，把任务随机保存在WorkQueues数组的偶数位；
         2. 开启或者唤醒ForkJoinWorkerThread线程从WorkQueues数组中获取ForkJoinTask任务。如果当前线程是新创建的，则需要绑定一个队列，后续该线程默认会消费该队列中的任务；
         3. 启动线程并从绑定的WorkQueue中获得任务，如果当前线程绑定的队列中没有任务，则会从其他队列中窃取任务并执行；
         4. 执行具体任务时会调用ForkJoinTask.exec()方法，exec()是一个抽象方法，具体的实现是由子类完成的。

## 八、阻塞队列

1. 概念
   |   队列名称   |功能|
   |:-----------:|:---|
   |ArrayBlockingQueue|由数组实现的有界阻塞队列，此队列按照“先进先出(FIFO)的原则”对元素进行排序|
   |LinkedBlockingQueue|由链表实现的有界阻塞队列，此队列的默认和最大长度为Integer.MAX_VALUE，队列按照“先进先出(FIFO)的原则”对元素进行排序|
   |PriorityBlockingQueue|支持优先级排序的无界阻塞队列，默认情况下元素按自然顺序升序排列，也可以通过自定义类实现compareTo()方法来指定元素排序规则；或者在初始化PriorityBlockingQueue时，指定构造参数Comparator来对元素进行排序|
   |DelayQueue|由优先级队列实现的支持延迟获取元素的无界阻塞队列|
   |SynchronousQueue|不存储元素的阻塞队列，每一个put操作必须等待一个take操作，否则不能继续添加元素|
   |LinkedTransferQueue|由链表实现的无界阻塞TransferQueue，相对其他阻塞队列，多了tryTransfer()和transfer()方法|
   |LinkedBlockingDeque|由链表实现的双向阻塞队列，双向阻塞队列的好处是在多线程入队时，可以减少竞争|
2. 实现原理：使用ReentrantLock来解决线程竞争问题，使用Condition来解决线程的唤醒与阻塞问题。