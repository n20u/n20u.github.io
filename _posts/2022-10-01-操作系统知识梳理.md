---
categories: [知识梳理]
---
# 操作系统知识梳理

## 操作系统

1. 特征
   - 并发
   - 共享
   - 虚拟
   - 异步

## 一、进程

1. 定义：操作系统为正在运行的程序提供的抽象，就是所谓的进程。
2. 构成：地址空间和寄存器，一些特殊的寄存器：程序计数器（Program Counter，PC）保存程序将要执行的下一条指令的地址，栈指针（stack pointer）和相关的帧指针（frame pointer）用于管理函数参数栈、局部变量和返回地址。
3. 创建：1、将代码和所有静态数据（例如初始化变量）惰性加载到内存中；2、为程序的运行时栈分配一些内存，也可能会用参数初始化栈，具体来说，会将参数填入main()函数，即argc和argv数组；3、为程序的堆分配一些内存；4、还会执行一些其他初始化任务，特别是与输入/输出（I/O）相关的任务。例如，在UNIX系统中，默认情况下每个进程都有3个打开的文件描述符（file descriptor），用于标准输入、输出和错误。
4. 执行：
   1. 受限制的操作：操作系统启动时，内核会告诉硬件陷阱表（trap table）在内存中的位置。程序要执行系统调用，必须执行特殊的陷阱（trap）指令。该指令查找陷阱表同时跳入内核并将特权级别提升到内核模式。一旦进入内核，系统就可以执行任何需要的特权操作（如果允许），从而为调用进程执行所需的工作。完成后，操作系统调用一个从陷阱返回（return-from-trap）指令，该指令返回到发起调用的用户程序中，同时将特权级别降低，回到用户模式。
   2. 切换进程：操作系统重获CPU的控制权的方式：1、协作方式：等待系统调用；2、非协作方式：时钟中断。切换进程时，操作系统会执行一些底层汇编代码，来保存正在执行的进程的通用寄存器、程序计数器，以及内核栈指针，然后恢复即将执行的进程的通用寄存器、程序计数器，以及内核栈指针。
5. 调度：
   1. 先进先出（First In First Out，FIFO）
   2. 最短任务优先（Shortest Job First，SJF）
   3. 最短完成时间优先（Shortest Time-to-Completion First，STCF）
   4. 轮转（Round-Robin，RR）
   5. 高响应比优先
   6. 多级反馈队列（Multi-level Feedback Queue，MLFQ）：有多个优先级不同的队列，优先执行较高优先级队列中的工作，对每个队列中的多个工作采用轮转调度。工作进入系统时，放在最高优先级队列中。一旦工作用完了其在某一优先级队列中的时间配额，就将其移入低一优先级队列。每过一段时间，就将系统中所有工作重新加入最高优先级队列。
   7. 比例份额（proportional-share）：彩票调度（lottery scheduling）和步长调度（stride scheduling）。
   8. 多处理器调度（multiprocessor scheduling）：单队列多处理器调度（Single Queue Multiprocessor Scheduling，SQMS），简单但缺乏可扩展性和缓存亲和性。多队列多处理器调度（Multi-Queue Multiprocessor Scheduling，MQMS），具有可扩展性和缓存亲和性，但负载不均（load imbalance）。
6. 状态

   ![进程状态](https://cdn.jsdelivr.net/gh/n20u/PicBed/blogs/knowledge_combing/20160906192211991.jpg)
7. 线程：同一个进程中的线程共享地址空间，发生切换时，只保存和恢复通用寄存器、程序计数器等，地址空间保持不变（即不需要切换当前使用的页表）。
8. 通信方式
   1. 管道：一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。
   2. 命名管道：一种半双工的通信方式，能在无亲缘关系的进程间使用。
   3. 信号：可以由硬件发出，也可以由其他进程调用kill函数发出，用于通知接收进程某个事件已经发生。
   4. 消息队列：消息的链表，具有特定的格式，存放在内存中并由消息队列标识符标识。
   5. 共享内存：内核专门留出了一块内存区，可以由需要访问的进程将其映射到自己的私有地址空间。进程可以直接读写这一块内存而不需要进行数据的拷贝，从而大大提高效率。由于多个进程共享一段内存，因此需要依靠某种同步机制（如信号量）来实现进程间的同步及互斥。
   6. 套接字：可以通过计算机网络在不同计算机上的进程之间通信。

## 二、虚拟内存

1. 定义：操作系统提供的一个易用的物理内存抽象，这个抽象叫作地址空间（address space），是运行的程序看到的系统中的内存。
2. 分段：一个段是地址空间里的一个连续定长的区域，给地址空间内的每个段（segment）引入一个基址和界限寄存器对，保存所有段的基址和界限等信息的内存结构叫作段表（segment table）。将虚拟地址分为段标识和段内偏移两部分，使用段标识来查找段的基址和界限等信息，然后将段内偏移与界限进行比较，大于界限的为非法地址，否则将段内偏移与基址相加，就得到了最终的物理地址。
3. 分页：将内存空间分割成固定长度的分片，为进程保存一个页表（page table），页表为地址空间中的每个虚拟页面保存了其所在的物理帧号（physical page number，PPN）。将虚拟地址分为虚拟页号（virtual page number，VPN）和页内偏移两部分，使用虚拟页号检索页表，得到其所在的物理帧号。然后使用物理帧号替换虚拟页号，就得到了最终的物理地址。
   1. 页表：页表由页表项（PTE）组成，每个页表项中除了物理帧号（PFN），还有许多不同的位。
      - 有效位（valid bit）：用于指示特定地址转换是否有效。
      - 保护位（protection bit）：表明页是否可以读取、写入或执行。
      - 存在位（present bit）：表示该页是在内存还是在磁盘上。
      - 脏位（dirty bit）：表明页面被带入内存后是否被修改过。
      - 参考位（reference bit，也被称为访问位，accessed bit）：用于追踪页是否被访问或确定哪些页很受欢迎。
   2. 地址转换旁路缓冲存储器（translation-lookaside buffer，TLB）：TLB中保存了若干条转换映射。转换虚拟地址时，首先从虚拟地址中提取虚拟页号，然后检查TLB是否有该虚拟页号的转换映射。如果有，就可以从相关的TLB项中取出物理帧号，与原来虚拟地址中的偏移量组合形成物理地址。如果没有，硬件系统会抛出一个异常，暂停当前的指令流，将特权级提升至内核模式，跳转至陷阱处理程序。然后查找页表中的转换映射，用特权指令更新TLB，从陷阱返回并重试指令。
   3. 段页式：为每个段提供一个页表，每个段的基址寄存器中保存了该段的页表的物理地址，界限寄存器中保存了该段中最大有效页的值。
   4. 多级页表：将页表分成页大小的单元，如果整页的页表项无效，就不分配该页的页表。
   5. 反向页表（inverted page table）：反向页表中的项代表系统的每个物理页，其指示哪个进程正在使用此页，以及该进程的哪个虚拟页映射到此物理页。
4. 空闲空间管理：
   1. 机制：空闲列表包含一组元素，记录了堆中的哪些空间还没有分配。申请内存时，分配程序找到一块可以满足请求的空闲空间，从中分割所需部分给用户，剩余部分留在空闲列表中。释放内存时，如果新归还的空间与一个原有空闲块相邻，就将它们合并为一个较大的空闲块，否则简单地将这块空闲空间加入空闲列表。
   2. 策略：
      1. 最优匹配（best fit）
      2. 最差匹配（worst fit）
      3. 首次匹配（first fit）
      4. 下次匹配（next fit）
      5. 分离空闲列表（segregated list）：如果应用程序经常申请一种（或几种）大小的内存空间，那就用独立的空闲列表只管理这样大小的对象，其他大小的请求都交给更通用的内存分配程序。
      6. 伙伴系统：
         二分伙伴分配程序（binary buddy allocator）：空闲空间被看成大小为$2^{N}$的大空间。申请内存时，空闲空间被递归地一分为二，直到刚好可以满足请求的大小。释放内存时，分配程序会检查释放的内存块的伙伴是否空闲，如果是，就合并成更大的空闲块，然后会检查这个更大的空闲块的伙伴是否空闲，如果是，就合并这两块。这个递归合并过程继续上溯，直到某一个块的伙伴还没有被释放，或者合并整个内存区域。
         伙伴系统运转良好的原因，在于很容易确定某个块的伙伴。在二分伙伴分配程序中，每对互为伙伴的块的起始地址只有一位不同，正是这一位决定了它们在整个伙伴树中的层次。
5. 超越物理内存：为每个进程同时提供巨大的地址空间
   1. 机制：
      - 交换空间：在硬盘上开辟的一部分空间，用于将内存中的页交换到其中，并在需要的时候交换回内存。
      - 修改页表：在页表中添加存在位表示该页是否在物理内存中，添加硬盘地址保存该页在交换空间中的位置。
      - 地址转换：硬件首先从虚拟地址获得虚拟页号，检查TLB是否命中，如果命中，则获得最终的物理地址并从内存中返回。如果未命中，则硬件使用页表基址寄存器在内存中查找页表，并使用虚拟页号作为索引查找该页的页表项。如果页有效且存在于物理内存中，则硬件从页表项中获得物理帧号，将其插入TLB，并重试该指令，这次产生TLB命中。如果页有效但不在物理内存中，操作系统将页从硬盘读取到内存中，在页表项中将此页标记为存在，更新物理帧号以记录该页的内存位置，并重试指令。下一次重新访问TLB还是未命中，然而这次因为页在内存中，因此会将页表中的地址更新到TLB中。最后的重试操作会在TLB中找到转换映射，从已转换的内存物理地址，获取所需的数据或指令。
   2. 策略：页错误发生后，操作系统需要将页从硬盘读取到内存中。当内存不够时，操作系统需要根据替换策略换出一些页。
      1. 最优替换策略
      2. 先进先出
      3. 随机
      4. 最不经常使用（Least-Frequently-Used，LFU）
      5. 最少最近使用（Least-Recently-Used，LRU）：
         - 时钟算法（clock algorithm）：将所有页放在一个循环列表中，时钟指针（clock hand）指向其中的页。如果当前指向的页的访问位为1，将其设置为0，时钟指针递增到下一页。一直持续到找到一个访问位为0的页，然后将该页替换。
         - 改进的时钟算法：
            1. 第一轮查找第一个（访问位，脏位）为（0，0）的页用于替换；
            2. 如果第一轮查找失败，则重新扫描，查找第一个（访问位，脏位）为（0，1）的页用于替换。本轮将所有扫描过的页的访问位设置为0；
            3. 如果第二轮查找失败，则重新扫描，查找第一个（访问位，脏位）为（0，0）的页用于替换。
            4. 如果第三轮查找失败，则重新扫描，查找第一个（访问位，脏位）为（0，1）的页用于替换。

## 三、同步原语

1. 锁
   1. 定义：锁就是一个变量，保存了锁在某一时刻的状态。它要么是可用的，表示没有线程持有锁，要么是被占用的，表示有一个线程持有锁，正处于临界区。
   2. 实现：
      1. 控制中断。
      2. 测试并设置（test-and-set）指令，或比较并交换（compare-and-swap）指令，或链接的加载和条件式存储指令，或获取并增加（fetch-and-add）指令，实现自旋锁。
      3. 使用队列：休眠替代自旋。
      4. 两阶段锁：第一阶段调用者会先自旋一段时间，希望它可以获取锁。如果第一个自旋阶段没有获得锁，第二阶段调用者会睡眠，直到锁可用。
   3. 基于锁的并发数据结构：
      1. 并发计数器：扩展方法：懒惰计数器。
      2. 并发链表：扩展方法：过手锁。
      3. 并发队列。
      4. 并发散列表。
2. 条件变量
   1. 定义：条件变量是一个显式队列，当某些执行状态不满足时，线程可以把自己加入队列，等待该条件。另外某个线程改变了上述状态时，就可以唤醒一个或者多个等待线程，让它们继续运行。
   2. 生产者/消费者（有界缓冲区）问题。
3. 信号量
   1. 定义：信号量是有一个整数值的对象，可以用两个函数来操作它。
   2. 用法：
      1. 用信号量作为锁：初始值设为1。
      2. 用信号量作为条件变量：初始值设为0。
      3. 生产者/消费者（有界缓冲区）问题。
      4. 读者——写者锁。
      5. 哲学家就餐问题。

## 五、死锁

1. 定义：死锁是指一组进程中的每个进程都在等待仅由该组进程的其它进程才能引发的事件。
2. 产生死锁的必要条件：
   - 互斥：进程对于需要的资源进行互斥的访问。
   - 持有并保持：进程持有了资源，同时又在等待其他资源。
   - 非抢占：进程获得的资源不能被抢占。
   - 循环等待：进程之间存在一个等待资源的环路。
3. 处理死锁的方法
   1. 预防死锁：破坏产生死锁的四个必要条件中的一个或几个来预防死锁。
      - 破坏“互斥”条件：设计不需要锁的数据结构，或利用假脱机技术将互斥资源在逻辑上改为共享资源。
      - 破坏“持有并保持”条件：进程在执行前，必须一次性申请所需的所有资源。
      - 破坏“非抢占”条件：进程提出的资源申请不能得到满足时，必须释放已经保持的资源或者让操作系统帮忙抢占资源。
      - 破坏“循环等待”条件：对系统所有资源类型进行线性编号，进程必须顺序申请资源，逆序释放资源。
   2. 避免死锁：在资源的动态分配过程中，防止系统进入不安全状态，从而避免死锁。例如银行家算法。
   3. 检测并解除死锁：不事先采取任何限制性措施，允许死锁偶尔发生，检测到死锁时再采取行动解除死锁。
      - 检测死锁：尝试对系统的资源分配图进行简化，当且仅当资源分配图不可完全简化时，系统中存在死锁。
      - 解除死锁：从一部分死锁进程中抢占资源分配给其他死锁进程，或终止若干个死锁进程。

## 六、持久性

1. I/O设备与主机信息传送的控制方式：
   1. 轮询：CPU通过程序不断查询I/O设备是否已做好准备，从而控制I/O设备与主机交换信息。
   2. 中断：CPU在启动I/O设备后，不查询设备是否已准备就绪，继续执行自身程序，只是当I/O设备准备就绪并向CPU发出中断请求后才予以响应。
   3. 直接内存访问（Direct Memory Access，DMA）：主存与I/O设备之间有一条数据通路，主存与I/O设备交换信息时，无须调用中断服务程序。
   4. I/O通道：通道是用来负责管理I/O设备以及实现主存与I/O设备之间交换信息的部件，可以视为一种具有特殊功能的处理器。
   5. I/O处理机：又称为外围处理机，基本独立于主机工作，既可完成I/O通道要完成的I/O控制，又可完成码制交换、格式处理、数据块检错、纠错等操作。
2. 磁盘驱动器：
   1. 磁盘调度：
      1. 最短寻道时间优先（Shortest-Seek-Time-First，SSTF）
      2. 电梯（SCAN）
         - F-SCAN
         - C-SCAN
      3. 最短定位时间优先（Shortest Positioning Time First，SPTF）
   2. 廉价冗余磁盘阵列（RAID）
      1. RAID 0级：条带化
      2. RAID 1级：镜像
      3. RAID 4级：通过奇偶校验节省空间
      4. RAID 5级：旋转奇偶校验
3. 文件系统

## 七、远程过程调用（RPC）

远程过程调用（Remote Procedure Call，RPC）是一个计算机通信协议，该协议使在远程机器上执行代码的过程像调用本地函数一样简单直接，它是一种进程间通信（Interprocess communication，IPC）的模式。
RPC系统通常由存根生成器（stub generator）和运行时库（run-time library）两部分组成：

- 存根生成器的输入是服务器希望导出到客户端的一组调用，输出是客户端存根和服务端存根。
  
  当客户端发起远程过程调用时，客户端存根执行以下操作：
  1. 创建消息缓冲区。消息缓冲区通常是个字节数组。
  2. 将所需信息打包到消息缓冲区中。该信息包括要调用的函数的标识符和传递给该函数的所有实参。将这些信息放入缓冲区的过程，称为参数的封送处理（marshaling）或消息的序列化（serialization）。
  3. 将消息发送到目标RPC服务器，等待回复。
  4. 解包返回结果。此步骤也称为解封送处理（unmarshaling）或反序列化（deserialization）。
  5. 返回调用者。从客户端存根返回到客户端代码。

  服务器存根的执行步骤如下：
  1. 解包消息。将信息从传入消息中取出，提取函数标识符和实参。此步骤称为解封送处理（unmarshaling）或反序列化（deserialization）。
  2. 调用实际函数。RPC运行时调用标识符指定的函数，并传入实参。
  3. 打包结果。将函数的返回结果封送处理，放入一个回复缓冲区。
  4. 发送回复。

- 运行时库处理RPC系统中的大部分繁重工作，大多数是性能和可靠性问题。例如：找到远程服务所在的服务器，与远程服务器通信等。

## 八、I/O多路复用

I/O多路复用是一种同步I/O模型，实现一个进程可以监听多个文件描述符，一旦有文件描述符准备就绪，能够通知进程进行相应的读写操作。
I/O多路复用有三种实现：
1. select
   1. 函数原型：
      ```C
      #include <sys/select.h>
      #include <sys/time.h>

      int select(int maxfdp1, fd_set *readset, fd_set *writeset, fd_set *exceptset, const struct timeval *timeout);
      ```
   2. 实现原理
      1. 将fd_set从用户空间拷贝到内核空间；
      2. 遍历所有fd，调用其对应的设备驱动的poll函数。该函数首先会将调用select的用户进程插入到该设备驱动对应资源的等待队列(如读/写等待队列)，然后返回一个bitmask告诉select当前资源哪些可用；
      3. 如果遍历完所有的fd，还没有返回一个可读写的bitmask，调用select的用户进程则会调用schedule_timeout进入睡眠。当设备驱动发现自身资源可读写后，会唤醒其等待队列上睡眠的进程。如果超过一定的超时时间(schedule_timeout指定)，还是没人唤醒，调用select的用户进程则会重新被唤醒获得CPU，进而重新遍历fd；
      4. 如果遍历完所有fd，返回了若干个可读写bitmask，则将对应的fd_set中的对应位置位，将fd_set从内核空间拷贝到用户空间。
   3. 缺点：
      1. 单个进程所打开的FD是有限制的，通过 FD_SETSIZE 设置，默认1024;
      2. 每次调用select，都需要将fd_set在用户态和内核态之间来回拷贝，这个开销在fd很多时会很大；
      3. 对socket扫描时是线性扫描，采用轮询的方法，效率较低（高并发）。
   4. pselect函数
      ```C
      #include <sys/select.h>
      #include <signal.h>
      #include <sys/time.h>

      int pselect(int maxfdp1, fd_set *readset, fd_set *writeset, fd_set *exceptset, const struct timespec *timeout, const sigset_t *sigmask);
      ```
2. poll
   1. 函数原型：
      ```C
      #include <poll.h>

      int poll(struct pollfd *fdarray, unsigned long nfds, int timeout);
      ```
   2. 实现原理
      与select相比，不再使用fd_set来传递事件和结果，而是使用pollfd结构体数组来传递。使用链表来存储fd，没有最大连接数的限制。
   3. 缺点：
      1. 每次调用poll，都需要将fd集合在用户态和内核态之间来回拷贝，这个开销在fd很多时会很大；
      3. 对socket扫描时是线性扫描，采用轮询的方法，效率较低（高并发）。
3. epoll
   1. 实现原理
      1. 调用epoll_create()函数创建并初始化一个eventpoll对象。eventpoll对象中包括：进程等待队列、已经就绪的fd链表、使用红黑树来管理的所有被监听的fd；
      2. 调用epoll_ctl()函数把被监听的文件句柄(如socket句柄)封装成epitem对象并且添加到eventpoll对象的红黑树中进行管理。并且会调用设备驱动的poll函数，把当前epitem对象添加到fd对象的等待队列中，当fd就绪时，将该epitem对象添加到eventpoll对象的就绪fd链表中；
      3. 调用epoll_wait()函数时，如果eventpoll对象的就绪fd链表不为空，则返回；否则把当前进程添加到eventpoll对象的进程等待队列中，等待fd就绪或者超时返回。
   2. 优点：
      1. 没有最大并发连接的限制，能打开的FD的上限远大于1024；
      2. 效率提升，只需要遍历就绪fd链表中的fd即可；
      3. 内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递，减少复制开销。
   3. 缺点：只能工作在linux下。
   4. LT 与 ET 模式的区别
      epoll 有 EPOLLLT 和 EPOLLET 两种触发模式，LT 是默认的模式，ET 是 “高速” 模式。
      - LT 模式下，只要这个 fd 还有数据可读，每次 epoll_wait 都会返回它的事件，提醒用户程序去操作；
      - ET 模式下，它只会提示一次，直到下次再有数据流入之前都不会再提示了，无论 fd 中是否还有数据可读。所以在 ET 模式下，read 一个 fd 的时候一定要把它的 buffer 读完，或者遇到 EAGIN 错误。